{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import gensim\n",
    "from torchcontrib.optim import SWA\n",
    "import os\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "torch.set_printoptions(edgeitems=768)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 设置基本参数\n",
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 16\n",
    "SEED = 9797\n",
    "NAME = 'HAN'\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE=='cuda':\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_ID</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>623 328 538 382 399 400 478 842 698 137 492 26...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48 328 538 382 809 623 434 355 382 382 363 145...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>623 656 293 851 636 842 698 493 338 266 369 69...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48 328 380 259 439 107 380 265 172 470 290 693...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>623 328 399 698 493 338 266 14 177 415 511 647...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>290 380 247 263 48 328 697 582 91 400 478 842 ...</td>\n",
       "      <td>0 7 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>852 611 501 582 177 230 294 39 363 180 519 421...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>852 328 290 380 256 544 636 90 735 374 698 116...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>852 328 305 461 382 697 259 779 59 261 589 693...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>722 623 411 382 570 399 328 380 728 672 846 48...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     report_ID                                        description   label\n",
       "0            0  623 328 538 382 399 400 478 842 698 137 492 26...       2\n",
       "1            1  48 328 538 382 809 623 434 355 382 382 363 145...        \n",
       "2            2  623 656 293 851 636 842 698 493 338 266 369 69...      15\n",
       "3            3  48 328 380 259 439 107 380 265 172 470 290 693...        \n",
       "4            4  623 328 399 698 493 338 266 14 177 415 511 647...      16\n",
       "...        ...                                                ...     ...\n",
       "9995      9995  290 380 247 263 48 328 697 582 91 400 478 842 ...  0 7 15\n",
       "9996      9996  852 611 501 582 177 230 294 39 363 180 519 421...      10\n",
       "9997      9997  852 328 290 380 256 544 636 90 735 374 698 116...        \n",
       "9998      9998  852 328 305 461 382 697 259 779 59 261 589 693...      16\n",
       "9999      9999  722 623 411 382 570 399 328 380 728 672 846 48...      16\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/track1_round1_train_20210222.csv',header=None)\n",
    "test_data = pd.read_csv('../data/track1_round1_testB.csv',header=None) \n",
    "train_data.columns=['report_ID','description','label']\n",
    "test_data.columns=['report_ID','description']\n",
    "\n",
    "temp=[i[:-1] for i in train_data['report_ID'].values]\n",
    "train_data['report_ID']=temp\n",
    "temp=[i[:-1] for i in test_data['report_ID'].values]\n",
    "test_data['report_ID']=temp\n",
    "\n",
    "temp=[i.strip('|').strip() for i in train_data['description'].values]\n",
    "train_data['description']=temp\n",
    "temp=[i.strip('|').strip() for i in test_data['description'].values]\n",
    "test_data['description']=temp\n",
    "\n",
    "temp_label=[i.strip('|').strip() for i in train_data['label'].values]\n",
    "train_data['label']=temp_label\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = pd.concat([train_data['description'],test_data['description']]).reset_index(drop=True)\n",
    "all_sentences.drop_duplicates().reset_index(drop=True, inplace=True)\n",
    "all_sentences = all_sentences.apply(lambda x:x.split(' ')).tolist()\n",
    "if not os.path.exists('w2v.model'): \n",
    "    w2v_model = gensim.models.word2vec.Word2Vec(all_sentences, sg=1, size=300,window=5,min_count=1,negative=3,sample=0.001,hs=1,seed=452)\n",
    "    w2v_model.save('w2v.model')\n",
    "else:\n",
    "    w2v_model = gensim.models.word2vec.Word2Vec.load(\"w2v.model\")\n",
    "    \n",
    "if not os.path.exists('fasttext.model'): \n",
    "    fasttext_model = gensim.models.FastText(all_sentences, seed=452, size=100, min_count=1, iter=20, window=3)\n",
    "    fasttext_model.save('fasttext.model')\n",
    "else:\n",
    "    fasttext_model = gensim.models.word2vec.Word2Vec.load(\"fasttext.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebae176142544df29941938efd61c7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597c28d0d5d0494b96a8fd87c3e1c45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    train_dict = {}\n",
    "    train_dict['report_ID'] = train_data.loc[i, 'report_ID']\n",
    "    train_dict['description'] = train_data.loc[i, 'description']\n",
    "    train_dict['label'] = train_data.loc[i, 'label']\n",
    "    train_dataset.append(train_dict)\n",
    "test_dataset = []\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    test_dict = {}\n",
    "    test_dict['report_ID'] = test_data.loc[i, 'report_ID']\n",
    "    test_dict['description'] = test_data.loc[i, 'description']\n",
    "    test_dict['label'] = ''\n",
    "    test_dataset.append(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c921c91235274a189907422d3b1ec892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d99e9f0ca144f288274f17722cb886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class DataSet(data.Dataset):\n",
    "    def __init__(self, data, mode='train'):\n",
    "        self.data = data\n",
    "        self.mode = mode\n",
    "        self.dataset = self.get_data(self.data,self.mode)\n",
    "        \n",
    "    def get_data(self, data, mode):\n",
    "        dataset = []\n",
    "        global s\n",
    "        for data_li in tqdm(data):\n",
    "            description = data_li['description'].split(' ')\n",
    "            description = [w2v_model.wv.vocab[s].index+1 if s in w2v_model.wv.vocab else 0 for s in description]\n",
    "            if len(description) < MAX_LEN:\n",
    "                description += [0] * (MAX_LEN - len(description))\n",
    "            else:\n",
    "                description = description[:MAX_LEN]\n",
    "            label = self.get_dumm(data_li['label'])\n",
    "            dataset_dict = {'description':description, 'label':label}\n",
    "            dataset.append(dataset_dict)\n",
    "        return dataset\n",
    "    \n",
    "    def get_dumm(self,s):\n",
    "        re = [0] * 17\n",
    "        if s == '':\n",
    "            return re\n",
    "        else:\n",
    "            tmp = [int(i) for i in s.split(' ')]\n",
    "            for i in tmp:\n",
    "                re[i] = 1\n",
    "        return re\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        description = torch.tensor(data['description'])\n",
    "        if self.mode == 'test':\n",
    "            return description\n",
    "        else:\n",
    "            label = torch.tensor(data['label'])\n",
    "            return description, label\n",
    "\n",
    "def get_dataloader(dataset, mode):\n",
    "    torchdata = DataSet(dataset, mode=mode)\n",
    "    if mode == 'train':\n",
    "        dataloader = torch.utils.data.DataLoader(torchdata, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "    elif mode == 'test':\n",
    "        dataloader = torch.utils.data.DataLoader(torchdata, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=False)\n",
    "    elif mode == 'valid':\n",
    "        dataloader = torch.utils.data.DataLoader(torchdata, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=False)\n",
    "    return dataloader, torchdata\n",
    "\n",
    "train_dataloader, train_torchdata = get_dataloader(train_dataset, mode='train')\n",
    "test_dataloader, test_torchdata = get_dataloader(test_dataset, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.W = nn.Linear(input_size, hidden_size, True)\n",
    "        self.u = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, x):\n",
    "        u = torch.tanh(self.W(x))\n",
    "        a = F.softmax(self.u(u), dim=1)\n",
    "        x = a.mul(x).sum(1)\n",
    "        return x\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes=17, embeddings=None):\n",
    "        super(HAN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        hidden_size_gru = 256\n",
    "        hidden_size_att = 512\n",
    "        hidden_size = 128\n",
    "        self.num_words = MAX_LEN\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if embeddings:\n",
    "            w2v_model = gensim.models.word2vec.Word2Vec.load(\"w2v.model\").wv\n",
    "            fasttext_model = gensim.models.word2vec.Word2Vec.load(\"fasttext.model\").wv\n",
    "            w2v_embed_matrix = w2v_model.vectors\n",
    "            fasttext_embed_matrix = fasttext_model.vectors\n",
    "#             embed_matrix = w2v_embed_matrix         \n",
    "            embed_matrix = np.concatenate([w2v_embed_matrix, fasttext_embed_matrix], axis=1)\n",
    "            oov_embed = np.zeros((1, embed_matrix.shape[1]))\n",
    "            embed_matrix = torch.from_numpy(np.vstack((oov_embed,embed_matrix)))\n",
    "            self.embed.weight.data.copy_(embed_matrix)\n",
    "            self.embed.weight.requires_grad = False\n",
    "        self.gru1 = nn.GRU(embedding_dim, hidden_size_gru, bidirectional=True, batch_first=True)\n",
    "        self.att1 = SelfAttention(hidden_size_gru * 2, hidden_size_att)\n",
    "        self.gru2 = nn.GRU(hidden_size_att, hidden_size_gru, bidirectional=True, batch_first=True)\n",
    "        self.att2 = SelfAttention(hidden_size_gru * 2, hidden_size_att)\n",
    "        self.tdfc = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.tdbn = nn.BatchNorm2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size_att,hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size,num_classes)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self, x, label=None):\n",
    "        # 64 512 200\n",
    "        x = x.view(x.size(0) * self.num_words, -1).contiguous()\n",
    "        x = self.dropout(self.embed(x))\n",
    "        x = self.tdfc(x).unsqueeze(1)\n",
    "        x = self.tdbn(x).squeeze(1)\n",
    "        x, _ = self.gru1(x)\n",
    "        x = self.att1(x)\n",
    "        x = x.view(x.size(0) // self.num_words, self.num_words, -1).contiguous()\n",
    "        x, _ = self.gru2(x)\n",
    "        x = self.att2(x)\n",
    "        out = self.dropout(self.fc(x))\n",
    "        if label is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(out.view(-1,self.num_classes).float(), label.view(-1,self.num_classes).float())\n",
    "            return loss\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_mlogloss(label,pred):\n",
    "    score = 0\n",
    "    for i in range(len(pred)):\n",
    "        for j in range(17):\n",
    "            if pred[i][j] == 0:\n",
    "                pred[i][j] +=1e-10\n",
    "            elif pred[i][j] == 1:\n",
    "                pred[i][j] -=1e-10\n",
    "            score += label[i][j]*np.log(pred[i][j])+(1-label[i][j])*np.log(1-pred[i][j])\n",
    "    score /= (len(pred)*17*(-1))\n",
    "    return 1-score\n",
    "\n",
    "def validation_funtion(model, valid_dataloader, valid_torchdata, mode='valid'):\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    labels_list = []\n",
    "    if mode == 'valid':\n",
    "        for i, (description, label) in enumerate(tqdm(valid_dataloader)):\n",
    "            output = model(description.to(DEVICE))\n",
    "            pred_list += output.sigmoid().detach().cpu().numpy().tolist()\n",
    "            labels_list += label.detach().cpu().numpy().tolist()\n",
    "        auc = roc_auc_score(labels_list,pred_list, multi_class='ovo')\n",
    "        logloss = log_loss(labels_list, pred_list)\n",
    "        mlogloss = metric_mlogloss(labels_list, pred_list)\n",
    "        return mlogloss, auc, logloss\n",
    "    else:\n",
    "        for i, (description) in enumerate(tqdm(valid_dataloader)):\n",
    "            output = model(description.to(DEVICE))\n",
    "            pred_list += output.sigmoid().detach().cpu().numpy().tolist()\n",
    "        return pred_list\n",
    "    \n",
    "                            \n",
    "def train(model, train_dataloader, valid_dataloader, valid_torchdata, epochs, early_stop=None):\n",
    "    global logger\n",
    "#     ema = EMA(model, 0.999)\n",
    "#     ema.register()\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    embed_pa = ['embed.weight']\n",
    "    optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in embed_pa)]},\n",
    "                                    {'params': model.embed.parameters(), 'lr': 2e-5}]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=1e-3, amsgrad=True, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2, eta_min=1e-5, last_epoch=-1)\n",
    "#     opt = SWA(optimizer, swa_start=100, swa_freq=5, swa_lr=1e-4)\n",
    "    total_loss = []\n",
    "    train_loss = []\n",
    "    best_mlogloss = -np.inf\n",
    "    best_auc = -np.inf\n",
    "    best_loss = np.inf\n",
    "    no_improve = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        if epoch > 2:\n",
    "            for param in model.named_parameters():\n",
    "                if param[0] == 'embed.weight':\n",
    "                    param[1].requires_grad = True\n",
    "                    break\n",
    "#         fgm = FGM(model)\n",
    "        bar = tqdm(train_dataloader)\n",
    "        for i, (description, label) in enumerate(bar):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(description.to(DEVICE), label.to(DEVICE))\n",
    "            loss = output\n",
    "            loss.backward()\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "#             fgm.attack()\n",
    "#             loss_adv = model(describe.to(DEVICE), label.to(DEVICE))\n",
    "#             loss_ad = loss_adv\n",
    "#             loss_ad.backward()\n",
    "#             fgm.restore()\n",
    "            \n",
    "            scheduler.step(epochs + i / len(train_dataloader))\n",
    "            optimizer.step()\n",
    "#             ema.update()\n",
    "            bar.set_postfix(tloss=np.array(train_loss).mean())\n",
    "#         opt.swap_swa_sgd()\n",
    "#         ema.apply_shadow()\n",
    "        mlogloss, auc, logloss = validation_funtion(model, valid_dataloader, valid_torchdata, 'valid')\n",
    "#         ema.restore()\n",
    "        print('train_loss: {:.5f}, mlogloss: {:.5f}, auc: {:.5f}, log_loss: {:.5f}\\n'.format(train_loss[-1],mlogloss,auc,logloss))\n",
    "        logger.info('Epoch:[{}]\\t mlogloss={:.5f}\\t auc={:.5f}\\t log_loss={:.5f}\\t'.format(epoch,mlogloss,auc,logloss))\n",
    "        global model_num\n",
    "        if early_stop:\n",
    "            if mlogloss > best_mlogloss:\n",
    "                best_mlogloss = mlogloss\n",
    "                best_auc = auc\n",
    "                best_loss = train_loss[-1]\n",
    "#                 ema.apply_shadow()\n",
    "                torch.save(model.state_dict(), '{}_model_{}.bin'.format(NAME, model_num))\n",
    "#                 ema.restore()\n",
    "            else:\n",
    "                no_improve += 1\n",
    "            if no_improve == early_stop:\n",
    "                model_num += 1\n",
    "                break\n",
    "            if epoch == epochs-1:\n",
    "                model_num += 1\n",
    "        else:\n",
    "            if epoch >= epochs-1:\n",
    "                torch.save(model.state_dict(), '{}_model_{}.bin'.format(NAME, model_num))\n",
    "                model_num += 1\n",
    "    return best_mlogloss, best_auc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "def get_logger(filename, verbosity=1, name=None):\n",
    "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level_dict[verbosity])\n",
    "    fh = logging.FileHandler(filename, \"w\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "    logger.removeHandler(sh)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 10\n",
    "kf = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=SEED)\n",
    "model_num = 1\n",
    "test_preds_total = collections.defaultdict(list)\n",
    "logger = get_logger('{}.log'.format(NAME))\n",
    "best_mlogloss = []\n",
    "best_auc = []\n",
    "best_loss = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(np.arange(train_data.shape[0]), train_data.label.values)):\n",
    "    print(str(i+1), '-'*50)\n",
    "    tra = [train_dataset[index] for index in train_index]\n",
    "    val = [train_dataset[index] for index in test_index]\n",
    "    print(len(tra))\n",
    "    print(len(val))\n",
    "    train_dataloader, train_torchdata = get_dataloader(tra, mode='train')\n",
    "    valid_dataloader, valid_torchdata = get_dataloader(val, mode='valid')\n",
    "    model = HAN(w2v_model.wv.vectors.shape[0]+1,w2v_model.wv.vectors.shape[1]+fasttext_model.wv.vectors.shape[1],embeddings=True)\n",
    "    model.to(DEVICE)\n",
    "    mlogloss,auc,loss = train(model,train_dataloader,\n",
    "                    valid_dataloader,\n",
    "                    valid_torchdata,\n",
    "                    epochs=100,\n",
    "                    early_stop=5)\n",
    "    torch.cuda.empty_cache()\n",
    "    best_mlogloss.append(mlogloss)\n",
    "    best_auc.append(auc)\n",
    "    best_loss.append(loss)\n",
    "for i in range(FOLD):\n",
    "    print('- 第{}折中，best mlogloss: {}   best auc: {}   best loss: {}'.format(i+1, best_mlogloss[i], best_auc[i], best_loss[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第1折中，best mlogloss: 0.9763843304205626   best auc: 0.9985805812897178   best loss: 0.3552546501159668\n",
    "- 第2折中，best mlogloss: 0.9774165140622638   best auc: 0.997005073232342   best loss: 0.3522224426269531\n",
    "- 第3折中，best mlogloss: 0.9772456548530228   best auc: 0.9980179860212681   best loss: 0.34420496225357056\n",
    "- 第4折中，best mlogloss: 0.9804633824677317   best auc: 0.9982196812576855   best loss: 0.32889825105667114\n",
    "- 第5折中，best mlogloss: 0.9783214461075509   best auc: 0.9982687191009312   best loss: 0.36440154910087585\n",
    "- 第6折中，best mlogloss: 0.9809039671615718   best auc: 0.9970804967779818   best loss: 0.3448050916194916\n",
    "- 第7折中，best mlogloss: 0.9774368164840502   best auc: 0.9980991573901716   best loss: 0.34063270688056946\n",
    "- 第8折中，best mlogloss: 0.973417946573173   best auc: 0.9983514048770021   best loss: 0.3517434895038605\n",
    "- 第9折中，best mlogloss: 0.9746748116688652   best auc: 0.9981369511507947   best loss: 0.3631766140460968\n",
    "- 第10折中，best mlogloss: 0.9709233344560553   best auc: 0.9974890027782815   best loss: 0.3433622121810913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d98120563a42c784edcc5cdf7e822b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a381e1f7976b4a9e8079b00689a68b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a6c8ac354f490a800c8ab6fbf8830b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2775d064951d4c38bc99b7bf9ad32160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7789a23a8e3c4d2380aa4a5bb50c536d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1901d570c854582a4068a630b768655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9f858866c5403bb980874c2ddad19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700497f37add48af8a26b95c3dad5a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c894f5f5348a40eaa6c82c0accdb6cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c7550dcdf64209a0100199786d6518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce139a9c641d474da41a8289b471e232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=188.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_num = 11\n",
    "model = HAN(w2v_model.wv.vectors.shape[0]+1,w2v_model.wv.vectors.shape[1]+fasttext_model.wv.vectors.shape[1],embeddings=True)\n",
    "model.to(DEVICE)\n",
    "test_preds_total = []\n",
    "test_dataloader, test_torchdata = get_dataloader(test_dataset, mode='test')\n",
    "for i in range(1,model_num):\n",
    "    model.load_state_dict(torch.load('{}_model_{}.bin'.format(NAME, i)))\n",
    "    test_pred_results = validation_funtion(model, test_dataloader, test_torchdata, 'test')\n",
    "    test_preds_total.append(test_pred_results)\n",
    "test_preds_merge = np.sum(test_preds_total, axis=0) / (model_num-1)\n",
    "pres_fold = [[str(p) for p in li] for li in test_preds_merge]\n",
    "pres_all = [' '.join(p) for p in pres_fold]\n",
    "str_w = ''\n",
    "sub_id = test_data['report_ID'].values\n",
    "with open('submit.csv','w') as f:\n",
    "    for i in range(len(sub_id)):\n",
    "        str_w += sub_id[i] + '|,' + '|' + pres_all[i] + '\\n'\n",
    "    str_w = str_w.strip('\\n')\n",
    "    f.write(str_w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
