{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Author  : nsytsqdtn\n",
    "# @Blog    ：https://www.nsytsqdtn.cn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import collections\n",
    "import re\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, roc_auc_score\n",
    "from transformers import BertForPreTraining, BertModel, BertTokenizer, AutoModel, AutoTokenizer\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "torch.set_printoptions(edgeitems=768)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BERT_MODEL_PATH = 'model'\n",
    "# 设置基本参数\n",
    "MAX_LEN = 50\n",
    "BATCH_SIZE = 32\n",
    "SEP_TOKEN_ID = 102\n",
    "SEED=20210214\n",
    "NAME = 'wwm'\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE=='cuda':\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 3), (25000, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/gaiic_track3_round1_train_20210228.tsv', sep='\\t', header=None)\n",
    "train_data.rename(columns={0:'sen1', 1:'sen2', 2:'labels'}, inplace=True)\n",
    "train_data['labels'] = train_data['labels'].astype(int)\n",
    "train_data = train_data.dropna().reset_index(drop=True)\n",
    "test_data = pd.read_csv('../data/gaiic_track3_round1_testB_20210317.tsv', sep='\\t', header=None)\n",
    "test_data.rename(columns={0:'sen1', 1:'sen2'}, inplace=True)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d059b87b11412e8b7b7bd6b70e1e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba4a6579aa34073820b78ac9e1edf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    train_dict = {}\n",
    "    train_dict['sen1'] = train_data.loc[i, 'sen1']\n",
    "    train_dict['sen2'] = train_data.loc[i, 'sen2']\n",
    "    train_dict['labels'] = train_data.loc[i, 'labels']\n",
    "    train_dataset.append(train_dict)\n",
    "test_dataset = []\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    test_dict = {}\n",
    "    test_dict['sen1'] = test_data.loc[i, 'sen1']\n",
    "    test_dict['sen2'] = test_data.loc[i, 'sen2']\n",
    "    test_dict['labels'] = None\n",
    "    test_dataset.append(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(data.Dataset):\n",
    "    def __init__(self, data, mode='train'):\n",
    "        self.data = data\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None)\n",
    "        self.mode = mode\n",
    "        self.dataset = self.get_data(self.data, self.tokenizer,self.mode)\n",
    "        \n",
    "    def get_data(self, data, tokenizer, mode):\n",
    "        global x\n",
    "        dataset = []\n",
    "        for data_li in tqdm(data):\n",
    "            sen1 = data_li['sen1']\n",
    "            sen2 = data_li['sen2']\n",
    "            labels = data_li['labels']\n",
    "            token1 = tokenizer.tokenize(sen1)[:MAX_LEN-3]\n",
    "            token2 = tokenizer.tokenize(sen2)[:MAX_LEN-len(token1)-3]\n",
    "            token_ids = tokenizer.convert_tokens_to_ids(['[CLS]']+token1+['[SEP]']+token2+['[SEP]'])[:MAX_LEN]\n",
    "            if len(token_ids) < MAX_LEN:\n",
    "                token_ids += [0] * (MAX_LEN - len(token_ids))\n",
    "            dataset_dict = {'sen1':sen1, 'sen2':sen2, 'token_ids':token_ids, 'labels':labels}\n",
    "            dataset.append(dataset_dict)\n",
    "        return dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        token_ids = torch.tensor(data['token_ids'])\n",
    "        seg_ids = self.get_seg_ids(token_ids)\n",
    "        if self.mode == 'test':\n",
    "            return token_ids, seg_ids\n",
    "        else:\n",
    "            labels = torch.tensor(data['labels'])\n",
    "            return token_ids, seg_ids, labels\n",
    "    \n",
    "    def get_seg_ids(self, ids):\n",
    "        seg_ids = torch.zeros_like(ids)\n",
    "        seg_idx = 0\n",
    "        for i, e in enumerate(ids):\n",
    "            seg_ids[i] = seg_idx\n",
    "            if e == SEP_TOKEN_ID:\n",
    "                seg_idx += 1\n",
    "        max_idx = torch.nonzero(seg_ids == seg_idx)\n",
    "        seg_ids[max_idx] = 0\n",
    "        return seg_ids\n",
    "\n",
    "def get_dataloader(dataset, mode):\n",
    "    torchdata = DataSet(dataset, mode=mode)\n",
    "    if mode == 'train':\n",
    "        dataloader = torch.utils.data.DataLoader(torchdata, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "    elif mode == 'test':\n",
    "        dataloader = torch.utils.data.DataLoader(torchdata, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=False)\n",
    "    elif mode == 'valid':\n",
    "        dataloader = torch.utils.data.DataLoader(torchdata, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=False)\n",
    "    return dataloader, torchdata\n",
    "\n",
    "# train_dataloader, train_torchdata = get_dataloader(train_dataset, mode='train')\n",
    "# test_dataloader, test_torchdata = get_dataloader(test_dataset, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_label():\n",
    "    train_dataloader, train_torchdata = get_dataloader(train_dataset, mode='train')\n",
    "    for token_ids, seg_ids, labels in train_dataloader:\n",
    "        print(token_ids)\n",
    "        print(seg_ids)\n",
    "        print(labels)\n",
    "        break\n",
    "# debug_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "def get_logger(filename, verbosity=1, name=None):\n",
    "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level_dict[verbosity])\n",
    "    fh = logging.FileHandler(filename, \"w\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "    logger.removeHandler(sh)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT_Model, self).__init__()\n",
    "        self.hidden_size = 768\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_PATH, output_hidden_states=True, return_dict=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input_ids, seg_ids, labels_ids=None):\n",
    "        attention_mask = (input_ids > 0)\n",
    "        out = self.bert(input_ids=input_ids, token_type_ids=seg_ids, attention_mask=attention_mask)\n",
    "        seq_relationship_score = F.sigmoid(self.dropout(self.linear(out[1])))\n",
    "        if labels_ids is not None:\n",
    "            loss_fct = nn.BCELoss()\n",
    "            loss = loss_fct(seq_relationship_score.view(-1,1).float(), labels_ids.view(-1,1).float())\n",
    "            return loss\n",
    "        else:\n",
    "            return seq_relationship_score\n",
    "\n",
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=0.5, emb_name='bert.embeddings.word_embeddings.weight'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='bert.embeddings.word_embeddings.weight'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name: \n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_funtion(model, valid_dataloader, valid_torchdata, mode):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    true_label = []\n",
    "    if mode != 'test':\n",
    "        for i, (sen1, sen2, label_ids) in enumerate(tqdm(valid_dataloader)):\n",
    "            output = model(sen1.to(DEVICE), sen2.to(DEVICE))\n",
    "            results += list(output.detach().cpu()) \n",
    "            true_label += list(label_ids)\n",
    "    else:\n",
    "        for i, (sen1, sen2) in enumerate(tqdm(valid_dataloader)):\n",
    "            output = model(sen1.to(DEVICE), sen2.to(DEVICE))\n",
    "            results += list(output.detach().cpu())    \n",
    "    if mode == 'valid':\n",
    "        auc = roc_auc_score(true_label,results)\n",
    "        acc = precision_score(true_label,[1 if i >= 0.5 else 0 for i in results])\n",
    "        recall = recall_score(true_label, [1 if i >= 0.5 else 0 for i in results])\n",
    "        f1 = f1_score(true_label, [1 if i >= 0.5 else 0 for i in results])\n",
    "        return auc, acc, recall, f1\n",
    "    else:\n",
    "        return results\n",
    "                            \n",
    "def train(model, train_dataloader, valid_dataloader, valid_torchdata, epochs, early_stop=None):\n",
    "    global logger\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "#     optimizer = BertAdam(optimizer_grouped_parameters, lr=2e-5)\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, amsgrad=True)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2)\n",
    "    total_loss = []\n",
    "    train_loss = []\n",
    "    best_score = -np.inf\n",
    "    no_improve = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        fgm = FGM(model)\n",
    "        bar = tqdm(train_dataloader)\n",
    "        for i, (input_ids, seg_ids, label_ids) in enumerate(bar):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_ids.to(DEVICE), seg_ids.to(DEVICE), label_ids.to(DEVICE))\n",
    "            loss = output\n",
    "            loss.backward()\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            fgm.attack()\n",
    "            loss_adv = model(input_ids.to(DEVICE), seg_ids.to(DEVICE), label_ids.to(DEVICE))\n",
    "            loss_ad = loss_adv\n",
    "            loss_ad.backward()\n",
    "            fgm.restore()\n",
    "            \n",
    "            scheduler.step(epoch + i / len(train_dataloader))\n",
    "            optimizer.step()\n",
    "            bar.set_postfix(tloss=np.array(train_loss).mean())\n",
    "        auc, accuracy, recall, f1 = validation_funtion(model, valid_dataloader, valid_torchdata, 'valid')\n",
    "        print('train_loss: {:.5f}, auc: {:.5f}, accuracy: {:.5f}, recall: {:.5f}, f1_socre: {:.5f}\\n'.format(train_loss[-1],auc,accuracy,recall,f1))\n",
    "        logger.info('Epoch:[{}]\\t auc={:.5f}\\t accuracy={:.5f}\\t recall={:.5f}\\t f1_socre={:.5f}'.format(epoch,auc,accuracy,recall,f1))\n",
    "        global model_num\n",
    "        if early_stop:\n",
    "            if auc > best_score:\n",
    "                best_score = auc\n",
    "                torch.save(model.state_dict(), '{}_model_{}.bin'.format(NAME, model_num))\n",
    "            else:\n",
    "                no_improve += 1\n",
    "            if no_improve == early_stop:\n",
    "                model_num += 1\n",
    "                break\n",
    "            if epoch == epochs-1:\n",
    "                model_num += 1\n",
    "        else:\n",
    "            if epoch >= epochs-2:\n",
    "                torch.save(model.state_dict(), '{}_model_{}.bin'.format(NAME, model_num))\n",
    "                model_num += 1\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 10\n",
    "kf = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=SEED)\n",
    "model_num = 1\n",
    "test_preds_total = collections.defaultdict(list)\n",
    "logger = get_logger('{}.log'.format(NAME))\n",
    "best_score = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(np.arange(train_data.shape[0]), train_data.labels.values)):\n",
    "    print(str(i+1), '-'*50)\n",
    "    tra = [train_dataset[index] for index in train_index]\n",
    "    val = [train_dataset[index] for index in test_index]\n",
    "    train_dataloader, train_torchdata = get_dataloader(tra, mode='train')\n",
    "    valid_dataloader, valid_torchdata = get_dataloader(val, mode='valid')\n",
    "    model = BERT_Model()\n",
    "    model.to(DEVICE)\n",
    "    score = train(model,train_dataloader,\n",
    "                    valid_dataloader,\n",
    "                    valid_torchdata,\n",
    "                    epochs=5)\n",
    "    torch.cuda.empty_cache()\n",
    "    best_score.append(score)\n",
    "for i in range(FOLD):\n",
    "    print('第{}折中，best auc: {}'.format(i+1, best_score[i]))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at zjcmodel and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247e905fd5b2424f89490d58f1680347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e278e73e232b4c73aa2d9901392b59d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a3f6b3e66145e5b61a7082e4d251bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacf60f74ac5446fa647dee5446fa736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26a30eb9bf944288aff8faa301a0776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff2131672444b7fa25b9c5bd09f7d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664233b5984343d1a0512d81a257c3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65765eb4bad43eb9f5f97733bcd7c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8d6c73bdf14e70a23d91475d25f6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f31311db5614d329e54815565fe29b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28733e7990f549abaf03212cf559d70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857549492ad64a7c97a55f308775b6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8cc07c493945c2aa2c7885e98790c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f7d49da779459fa7e92fbf5831e5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4260d6883d469d994162eefd527fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844158d8805748bc910ff0b286fa758e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c749f4f34724ee8b2e6c4d0d52c1861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4af7a5d55245c58f825150b6d5a322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc55d1f81cc74ab58d20ee4ffe7b967c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fd2e553812496592859613bcf1c5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35d0653396e4822ac22bcca30b46b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_num = 21\n",
    "model = BERT_Model()\n",
    "model.to(DEVICE)\n",
    "test_preds_total = []\n",
    "test_dataloader, test_torchdata = get_dataloader(test_dataset, mode='test')\n",
    "for i in range(1,model_num):\n",
    "    model.load_state_dict(torch.load('{}_model_{}.bin'.format(NAME, i)))\n",
    "    test_pred_results = validation_funtion(model, test_dataloader, test_torchdata, 'test')\n",
    "    test_preds_total.append(test_pred_results)\n",
    "test_preds_merge = np.sum(test_preds_total, axis=0) / (model_num-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "f = open('2_submit.txt','w')\n",
    "for x in test_preds_merge:\n",
    "    f.write(str(x)+'\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
